\subsection{Задача классификации при обучении с учителем}

В общем виде задача текстовой классификации определяется следующим 
образом~\cite{Manning2008}. 
Пусть существует описание документа $d \in \mathbb{X}$, где $\mathbb{X}$ --- векторное пространство документов, и фиксированный набор классов 
$\mathbb{C} = \setof{c_1, c_2, \ldots, c_m}$. 
Из обучающей выборки (множества документов с заранее известными классами)
$\mathbb{D} = \{\tuple{d, c} \mid \tuple{d, c} \in \mathbb{X} \times \mathbb{C}\}$
с помощью метода обучения $\Gamma$ необходимо получить классифицирующую 
функцию (или классификатор) 
$\Gamma(\mathbb{D}) = \gamma$, которая отображает документы в классы $\gamma: \mathbb{X} \rightarrow \mathbb{C}$.

В задаче определения тональности множество $\mathbb{C}$ состоит 
из двух элементов \{положительный, отрицательный\}.

\subsubsection{Представление данных}
Все документы из обучающей и тестовой выборки представляют собой $n$-мерные признаковые векторы 
(англоязычное название \textit{feature vector}, однако не стоит путать признаки с аспектами). 

В задачах обработки текста на естественном языке популярно представление 
документов в виде $n$-грамм, где $n$-граммы --- последовательности слов длины $n$. 
Для $n = 1$ такая последовательность состоит из одного слова и называется 
юниграммой (модель, которая использует представление в виде юниграмм 
называется ``набор слов'' (\textit{bag-of-words}), так как слова рассматриваются 
независимо друг от друга). Для $n = 2$ такая последовательность называется биграммой, и т.д.

Например, для высказывания ``Сегодня отличный день!'' множество юниграмм 
будет состоять из элементов \{``Сегодня'', ``отличный'', ``день!''\}, а множество
биграмм \{``Сегодня\_отличный'', ``отличный\_день!''\}. 
Стоит отметить, что с ростом $n$, $n$-граммы всё точнее 
отражают оригинальный текст, а потому их ценность
для моделирования произвольного текста падает (в задачах текстовой 
классификации редко используется $n > 3$). Теоретически, использование биграмм
даёт возможность моделировать значение тональности более точно: если 
рассматривать словосочетание ``не нравится'', как набор независимых слов, то
он содержит одно слово с отрицательной тональностью
и одно с положительной, поэтому
классификатор может посчитать, что общая тональность будет близка к нулевой. С 
другой стороны, маловероятно, что биграмма ``не\_нравится'' 
будет использована в положительном контексте.

Таким образом документ определяется как вектор $d = (w_1, w_2, \ldots , w_{|\mathbb{V}|}) $,
где $\mathbb{V}$ --- множество всех уникальных термов из 
обучающей выборки. 

$w_i$ --- вес i-го терма. Популярные способы взвешивания~\cite{wiki_vectorspace}:
\begin{enumerate}

\item 
Булевский вес --- $w_i = 1$ если терм присутствует в документе, иначе 0.

\item
Количество вхождений i-го терма в $d$ 
\begin{equation} 
w_i = n_i
\end{equation}

\item
Частота терма (\textit{TF --- term frequency}) --- отношение числа вхождений i-го терма к общему количеству термов документа.

\begin{equation} 
w_i = tf(t_i, d) = \frac{n_i}{\sum n_k}
\end{equation}

\item
TF-IDF (\textit{IDF --- inverse document frequency}, обратная частота документа) 

\begin{equation} 
idf(t, \mathbb{D} ) = \log \frac{|\mathbb{D}|}{| (d_i \supset t_i) |}
\end{equation}

\begin{equation} 
w_i = tfidf(t_i, d, \mathbb{D} ) = tf(t_i, d) \times idf(t, \mathbb{D} )
\end{equation}

где $|\mathbb{D}|$ --- количество документов в корпусе, $| (d_i \supset t_i) |$ ---
количество документов, в которых встречается $t_i$.

\end{enumerate}


\subsubsection{Определение качества работы классификатора}

Чтобы сравнивать алгоритмы классификации необходимо 
ввести меру оценки качества работы.

Для этого необходима тестовая выборка с заранее известными классами.
По результату работы обученного классификатора на тестовой выборке
для каждого класса считаются следующие значения~\cite{classifier_performance}:
\begin{itemize}
\item $TP$--- количество истинно-положительных результатов.
\item $TN$ --- количество истинно-отрицательных результатов.
\item $FP$ --- количество ложно-положительных результатов.
\item $FN$ --- количество ложно-отрицательных результатов.
\end{itemize}

На основе этих значений считаются меры точности (\textit{precision}) 
и полноты (\textit{recall}):

\begin{equation}
Precision = \frac{TP}{TP+FP}
\end{equation}

\begin{equation}
Recall = \frac{TP}{TP+FN}
\end{equation}

Их смысл в следующем: точность --- доля результатов, которая действительно
принадлежит данному классу, а полнота --- процент найденных результатов
от их общего числа.

Так как при стремлении любой из этих величин к нулю, ценность классификатора 
падает, то для усреднения обоих значений определяется $F_1$-мера, как 
гармоническое среднее точности и полноты:

\begin{equation}
F_1 = \frac{2 (Precision + Recall)}{Precision Recall}
\end{equation}

В отличии от среднего арифметического в случае, если $Precision = 0$, а $Recall = 1$ (или наоборот), среднее будет равняться нулю, а не $\frac{1}{2}$.

Для того, чтобы избежать проблемы переобучения (\textit{overfitting}),
когда модель слишком хорошо работает на примерах, но плохо на реальных данных,
для проверки модели используется метод перекрёстной проверки (\textit{cross-validation}). 
Вся обучающая выборка делится на $k$-частей, затем $\forall i \in \{1, 2, \ldots , k\}$
алгоритм классификации обучается на на всей обучающей выборке, кроме части i,
а тестируется на $i$-й части. Результатом работы считается среднее 
арифметическое по всем проходам. Часто значение $k$ принимают равным 5 или 10.