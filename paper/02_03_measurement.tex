\subsection{Оценка качества работы алгоритмов}

Оценка алгоритмов в задаче определения тональности проводилась на основе 
тестирования на двух англоязычных размеченных корпусах: Sanders~\cite{sanders} и SemEval-2013~\cite{semeval},
из которых были удалены нейтральные твиты. Первый корпус содержит 
сообщения из области брендов, второй --- из смешанных областей.


\begin{table}[h]
\caption{Числовые характеристики корпусов.}

	\begin{center}
	    \begin{tabular}{ | l | l | l | l | l | l |}
	    \hline
	    Корпус & Полож. & Отриц. & Всего & Юниграммы & Биграммы \\ \hline
	    Sanders & 502 & 547 & 1049 & 5425 & 12119 \\ \hline
	    SemEval & 3742 & 1565 & 5307 & 25538 & 70775\\ \hline
	    \hline
	    \end{tabular}
	\end{center}
\end{table}


\subsubsection{Нормализация данных}
Перед проверкой алгоритмов необходимо нормализовать данные
для уменьшение размерности и уменьшения ``зашумленности'' данных. 

В качестве способов нормализации использовались:
\begin{enumerate}

\item
Приведение всех букв к нижнему регистру.

\item
Замена всех гиперссылок на токен ``URL''.

\item
Замена всех упоминаний пользователей на токен ``MENTION''.

\item
Замена всех смайликов на токен ``POSITIVE\_SMILEY'' или ``NEGATIVE\_SMILEY'' в 
зависимости от тональности. Замена производилась с помощью регулярных
выражений, список смайликов взят из Википедии~\cite{emoticons}.

\item
Удаление всех хештэгов.

\item
Так как в современном английском не употребляются слова, в которых подряд
идут три и более одинаковых символов, то все такие вхождения заменялись на два символа (``gooood'' и ``goood'' заменяются на ``good'').

\item
Удаление символов пунктуации и замена непечатных символов (табуляции, перевода строки) на пробел.

\end{enumerate}

\begin{table}[h]
\caption{Количество n-грамм после нормализации.}

	\begin{center}
	    \begin{tabular}{ | l | l | l | }
	    \hline
	    Корпус & $n = 1$ & $n = 2$ \\ \hline
	    Sanders &  2871 & 9842 \\ \hline
	    SemEval & 12241 & 58486\\ \hline
	    \hline
	    \end{tabular}
	\end{center}
\end{table}

\subsubsection{Тестирование}

\begin{table}[h]
\caption{Результаты тестирования.}
\newcommand{\mc}[3]{\multicolumn{#1}{#2}{#3}}
	\begin{center}
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|}
\hline 
\mc{3}{|c|}{Классификатор} & \mc{6}{|c|}{Корпус}\\ \hline

Алгоритм & N-грамм & Вес & \mc{3}{|c|}{Sanders} & \mc{3}{|c|}{SemEval}\\ \hline

  &   &   & Precision & \mc{1}{|c|}{Recall} & \mc{1}{|c|}{F1} & \mc{1}{|c|}{Precision} & \mc{1}{|c|}{Recall} & \mc{1}{|c|}{F1}\\ \hline
NaiveBayes & 1 & Boolean & \mc{1}{|c|}{0.800} & 0.756 & 0.751 & 0.376 & 0.498 & 0.413\\ \hline
  &   & Count & \mc{1}{|c|}{0.799} & 0.756 & 0.751 & 0.401 & 0.499 & 0.413\\ \hline
  & 2 & Boolean & \mc{1}{|c|}{0.714} & 0.701 & 0.698 & 0.766 & 0.544 & 0.506\\ \hline
  &   & Count & \mc{1}{|c|}{0.709} & 0.698 & 0.695 & 0.768 & 0.545 & 0.508\\ \hline
  & 1+2 & Boolean & \mc{1}{|c|}{0.792} & 0.762 & 0.759 & 0.720 & 0.510 & 0.437\\ \hline
  &   & Count & \mc{1}{|c|}{0.795} & 0.765 & 0.762 & 0.719 & 0.509 & 0.436\\ \hline
MaxEnt & 1 & Boolean & \mc{1}{|c|}{0.680} & 0.630  & 0.609 &   &   &  \\ \hline
  & 2 & Boolean & \mc{1}{|c|}{0.686} &  0.679 & 0.678 &   &   &  \\ \hline
  & 1+2 & Boolean & \mc{1}{|c|}{0.689} & 0.637  & 0.617  &   &   &  \\ \hline
\end{tabular}
\end{center}

\end{table}

Все алгоритмы были реализованы на языке программирования Python
с применением библиотеки Numpy для быстрых векторных операций.
Для градиентного подъёма в методе максимальной энтропии
были вручную подобраны параметры для приемлемого соотношения
между временем сходимости и качеством работы. 

Из-за времени занимаемого на каждую итерацию (более получаса) метод 
максимальной энтропии не был протестирован на корпусе SemEval. 

Тестирование проходило с помощью 10-кратной перекрёстной проверки
путём усреднения результатов итераций и затем усреднения результатов по 
классам.

Для сравнения был также использован словарный метод (использовался словарь~\cite{dictionary}, содержащий 6800 слов).