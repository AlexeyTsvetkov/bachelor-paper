\subsection{Оценка качества работы алгоритмов}

Оценка алгоритмов в задаче определения тональности проводилась на основе 
тестирования на двух англоязычных размеченных корпусах: Sanders~\cite{Sanders} и SemEval-2013~\cite{SemEval2013},
из которых были удалены нейтральные твиты. Первый корпус содержит 
сообщения из области брендов, второй --- из смешанных областей.


\begin{table}[h]
\caption{Числовые характеристики корпусов.}

	\begin{center}
	    \begin{tabular}{ | l | l | l | l | l | l |}
	    \hline
	    Корпус & Полож. & Отриц. & Всего & Юниграммы & Биграммы \\ \hline
	    Sanders & 502 & 547 & 1049 & 5425 & 12119 \\ \hline
	    SemEval & 3742 & 1565 & 5307 & 25538 & 70775\\ \hline
	    \hline
	    \end{tabular}
	\end{center}
\end{table}


\subsubsection{Нормализация данных}
Перед проверкой алгоритмов необходимо нормализовать данные
для уменьшение размерности и уменьшения ``зашумленности'' данных. 

В качестве способов нормализации использовались:
\begin{enumerate}

\item
Приведение всех букв к нижнему регистру.

\item
Замена всех гиперссылок на токен ``URL''.

\item
Замена всех упоминаний пользователей на токен ``MENTION''.

\item
Замена всех смайликов на токен ``POSITIVE\_SMILEY'' или ``NEGATIVE\_SMILEY'' в 
зависимости от тональности. Замена производилась с помощью регулярных
выражений, список смайликов взят из Википедии~\cite{emoticons}.

\item
Удаление всех хештэгов.

\item
Так как в современном английском не употребляются слова, в которых подряд
идут три и более одинаковых символов, то все такие вхождения заменялись на два символа (``gooood'' и ``goood'' заменяются на ``good'').

\item
Удаление символов пунктуации и замена непечатных символов (табуляции, перевода строки) на пробел.

\end{enumerate}

\begin{table}[h]
\caption{Количество n-грамм после нормализации.}

	\begin{center}
	    \begin{tabular}{ | l | l | l | }
	    \hline
	    Корпус & $n = 1$ & $n = 2$ \\ \hline
	    Sanders &  2871 & 9842 \\ \hline
	    SemEval & 12241 & 58486\\ \hline
	    \hline
	    \end{tabular}
	\end{center}
\end{table}

\subsubsection{Тестирование}

\begin{table}[h]
\caption{Результаты тестирования.}
\newcommand{\mc}[3]{\multicolumn{#1}{#2}{#3}}
	\begin{center}
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|}
\hline 
\mc{3}{|c|}{Классификатор} & \mc{6}{|c|}{Корпус}\\ \hline

Алгоритм & N-грамм & Вес & \mc{3}{|c|}{Sanders} & \mc{3}{|c|}{SemEval}\\ \hline

  &   &   & Precision & \mc{1}{|c|}{Recall} & \mc{1}{|c|}{$F_1$} & \mc{1}{|c|}{Precision} & \mc{1}{|c|}{Recall} & \mc{1}{|c|}{$F_1$}\\ \hline

 NaiveBayes  & 1  & Count & \mc{1}{|c|}{{\bf0.799}} & 0.756 & 0.751 & 0.401 & 0.499 & 0.413\\ \hline

  & 2 & Count & \mc{1}{|c|}{0.709} & 0.698 & 0.695 & \bf{0.768} & 0.545 & 0.508\\ \hline

  &  1+2 & Count & \mc{1}{|c|}{0.795} & {\bf0.765} & {\bf0.762} & 0.719 & 0.509 & 0.436\\ \hline

MaxEnt & 1 & Boolean & \mc{1}{|c|}{0.680} & 0.630  & 0.609 &   &   &  \\ \hline

  & 2 & Boolean  & \mc{1}{|c|}{0.686} &  0.679 & 0.678 &   &   &  \\ \hline

  & 1+2 & Boolean  & \mc{1}{|c|}{0.689} & 0.637  & 0.617  &   &   &  \\ \hline

 Dictionry & & & \mc{1}{|c|}{0.714} & 0.675  & 0.651  & 0.758  & \bf{0.697}  & \bf{0.714} \\ \hline
\end{tabular}
\end{center}

\end{table}

Тестирование проходило с помощью 10-кратной перекрёстной проверки
путём усреднения результатов итераций и затем усреднения результатов по 
классам.

Для сравнения был также использован словарный метод (использовался словарь~\cite{dictionary}, содержащий 6800 слов).

Все алгоритмы были реализованы на языке программирования Python
с применением библиотеки Numpy для быстрых векторных операций.
Для градиентного подъёма в методе максимальной энтропии
были вручную подобраны параметры для приемлемого соотношения
между временем сходимости и качеством работы. 

Из-за времени занимаемого на каждую итерацию (более получаса) метод 
максимальной энтропии не был протестирован на корпусе SemEval. 

На корпусе Sanders наивный Байесовский классификатор показал значительное
превосходство и над словарным методом, и над методом максимальной энтропии.
ММЭ показал результаты на уровне словарного метода, при этом время его работы
занимало существенно большее время. В целом, наилучшие результаты были достигнуты при использовании юниграмм и биграмм в качестве признаков и наивного Байеса в качестве классификатора.

На корпусе SemEval Байесовский классификатор показал немного большую 
точность, однако значение полноты и $F_1$ оказалось на целых 20\% ниже, 
чем у словарного метода. Возможно это связано с тем, что сообщения
в обучающей выборке сильно смещены в сторону положительного класса.
Также стоит заметить, что если первый корпус состоит из сообщений одной области (бренды), 
то второй состоит из сообщений разных областей, поэтому свою роль
могла сыграть зависимость от домена.